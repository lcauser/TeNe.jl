var documenterSearchIndex = {"docs":
[{"location":"tensors/#Tensors","page":"Tensors","title":"Tensors","text":"","category":"section"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"Pages = [\"tensors.md\"]\r\nDepth = 3","category":"page"},{"location":"tensors/#Tensor-operations","page":"Tensors","title":"Tensor operations","text":"","category":"section"},{"location":"tensors/#Tensor-contraction","page":"Tensors","title":"Tensor contraction","text":"","category":"section"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"Contract two tensors x and y over dimensions cix and ciy with a shared size. This can be done in place with a pre-allocated tensor z using contract!(z, x, y, cix, ciy), or otherwise contract(x, y, cix, ciy). The dimensions cix and ciy can be specified as integers or tuples of integers for contractions over multiple dimensions. Optionally, the tensors used in the contraction can be conjugated using the arguments conjx and conjy. Note that, by default, the result will be stored in the memory cache (using keyword argument tocache). If the contraction is not some intermediate step, and you would like to save the resulting tensor for future use, then use tocache=false.","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"contract!\r\ncontract","category":"page"},{"location":"tensors/#TeNe.contract!","page":"Tensors","title":"TeNe.contract!","text":"contract!(z, x, y, cix, ciy, [conjx=false, conjy=false])\n\nContract tensors x and y across dimensions cix and ciy, and store the result in z. In-place version of contract.\n\nArguments\n\n- `z`: tensor to store the result.\n- `x`: first tensor to contract.\n- `y': second tensor to contract.\n- `cix`: the dimensions of the first tensor to contract.\n- `ciy`: the dimensions of the second tensor to contract.\n- `conjx::Bool=false`: Take the complex conjugate of argument x?\n- `conjy::Bool=false`: Take the complex conjugate of argument y?\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3, 4);\njulia> y = randn(ComplexF64, 3, 5, 6);\njulia> z = similar(x, (2, 4, 5, 6));\njulia> contract!(z, x, y, 2, 1)\n\n\n\n\n\n","category":"function"},{"location":"tensors/#TeNe.contract","page":"Tensors","title":"TeNe.contract","text":"contract(x, y, cix, ciy, [conjx=false, conjy=false]; kwargs...)\n\nContract tensors x and y across dimensions cix and ciy, and returns it as z.\n\nArguments\n\n- `x`: first tensor to contract.\n- `y': second tensor to contract.\n- `cix`: the dimensions of the first tensor to contract.\n- `ciy`: the dimensions of the second tensor to contract.\n- `conjx::Bool=false`: Take the complex conjugate of argument x?\n- `conjy::Bool=false`: Take the complex conjugate of argument y?\n\nOptional Keyword Arguments\n\n- `tocache::Bool=true`: store the result in the second level of the cache?\n- `sublevel=:auto`: if stored in cache, at which sublevel? :auto finds non-aliased memory\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3, 4);\njulia> y = randn(ComplexF64, 3, 5, 6);\njulia> z = contract(x, y, 2, 1);\njulia> size(z)\n(2, 4, 5, 6)\n\njulia> x = randn(ComplexF64, 2, 3, 4, 5);\njulia> y = randn(ComplexF64, 6, 5, 2, 7);\njulia> z = contract(x, y, (1, 4), (3, 2));\njulia> size(z)\n(3, 4, 6, 7)\n\n\n\n\n\n","category":"function"},{"location":"tensors/#Tensor-product","page":"Tensors","title":"Tensor product","text":"","category":"section"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"Take the tensor product over two tensors x and y to give a single tensor. This can be done in place with a pre-allocated tensor z using tensorproduct!(z, x, y), or otherwise tensorproduct(x, y). Optionally, the tensors used in the product can be conjugated using the arguments conjx and conjy. Note that, by default, the result will be stored in the memory cache (using keyword argument tocache). If the result is not some intermediate step, and you would like to save the resulting tensor for future use, then use tocache=false.","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"tensorproduct!\r\ntensorproduct","category":"page"},{"location":"tensors/#TeNe.tensorproduct!","page":"Tensors","title":"TeNe.tensorproduct!","text":"tensorproduct!(z, x, y, [conjx=false, conjy=false])\n\nCompute the tensor product of the two tensors x and y, and store the  result in z. Optionally, do the tensor product using the conjugate of the tensors.\n\nArguments\n\n- `z`: tensor to store the result.\n- `x`: first tensor.\n- `y': second tensor.\n- `conjx::Bool=false`: Take the complex conjugate of argument x?\n- `conjy::Bool=false`: Take the complex conjugate of argument y?\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3);\njulia> y = randn(ComplexF64, 4, 5);\njulia> z = similar(x, (2, 3, 4, 5));\njulia> tensorproduct!(z, x, y);\n\n\n\n\n\n","category":"function"},{"location":"tensors/#TeNe.tensorproduct","page":"Tensors","title":"TeNe.tensorproduct","text":"tensorproduct(x, y, [conjx=false, conjy=false])\n\nCompute the tensor product of the two tensors x and y, and store the  result in z. Optionally, do the tensor product using the conjugate of the tensors.\n\nArguments\n\n- `x`: first tensor.\n- `y': second tensor.\n- `conjx::Bool=false`: Take the complex conjugate of argument x?\n- `conjy::Bool=false`: Take the complex conjugate of argument y?\n\nOptional Keyword Arguments\n\n- `tocache::Bool=true`: store the result in the second level of the cache?\n- `sublevel=:auto`: if stored in cache, at which sublevel? :auto finds non-aliased memory\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3);\njulia> y = randn(ComplexF64, 4, 5);\njulia> z = tensorproduct(x, y);\njulia> size(z)\n(2, 3, 4, 5)\n\n\n\n\n\n","category":"function"},{"location":"tensors/#Tensor-trace","page":"Tensors","title":"Tensor trace","text":"","category":"section"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"Compute the trace over multiple dimensions cix in a tensor x. This can be done in place with a pre-allocated tensor z using trace!(z, x, cix...), or otherwise trace(x, cix...). Optionally, the tensor used in the trace can be conjugated using the key word argument conj. Note that, by default, the result will be stored in the memory cache (using keyword argument tocache). If the result is not some intermediate step, and you would like to save the resulting tensor for future use, then use tocache=false.","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"trace!\r\ntrace(x, cix::Int...)","category":"page"},{"location":"tensors/#TeNe.trace!","page":"Tensors","title":"TeNe.trace!","text":"trace!(z, x, cix::Int...; kwargs)\n\nCompute the trace of xover dimensionscix, and store the result inz`. In place version of trace.\n\nOptional Keyword Arguments\n\n- 'conj::Bool=false': take the conjugate?\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3, 4, 3);\njulia> z = similar(x, (2, 4));\njulia> trace!(z, x, (2, 4));\n\n\n\n\n\n","category":"function"},{"location":"tensors/#TeNe.trace-Tuple{Any, Vararg{Int64}}","page":"Tensors","title":"TeNe.trace","text":"trace(x, cix::Int...; kwargs)\n\nCompute the trace of x over dimensions cix.\n\nOptional Keyword Arguments\n\n- `conj::Bool=false`: take the conjugate?\n- `tocache::Bool=true`: store the result in the second level of the cache?\n- `sublevel=:auto`: if stored in cache, at which sublevel? :auto finds non-aliased memory\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3, 4, 3);\njulia> y = trace(x, 2, 4);\njulia> size(y)\n(2, 4)\n\n\n\n\n\n","category":"method"},{"location":"tensors/#Permuting-a-single-dimension","page":"Tensors","title":"Permuting a single dimension","text":"","category":"section"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"Permute the dimension at position i in tensor x to position j. This can be done in place with a pre-allocated tensor z using permutedim!(z, x, i, j), or otherwise permutedim(x, i, j). Note that, by default, the result will be stored in the memory cache (using keyword argument tocache). If the result is not some intermediate step, and you would like to save the resulting tensor for future use, then use tocache=false.","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"permutedim!\r\npermutedim","category":"page"},{"location":"tensors/#TeNe.permutedim!","page":"Tensors","title":"TeNe.permutedim!","text":"permutedim!(z, x, i, j; kwargs...)\n\nPermute dimension i to j for tensor x. Store the result in z. In place version of permutedim.\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3, 4, 5);\njulia> z = similar(x, (2, 4, 5, 3));\njulia> permutedims!(z, x, 2, 4);\n\n\n\n\n\n","category":"function"},{"location":"tensors/#TeNe.permutedim","page":"Tensors","title":"TeNe.permutedim","text":"permutedim(x, i::Int, j::Int; kwargs...)\n\nPermute dimension with position i to position j for tensor x.\n\nOptional Keyword Arguments\n\n- `tocache::Bool=true`: store the result in the second level of the cache?\n- `sublevel=:auto`: if stored in cache, at which sublevel? :auto finds non-aliased memory\n\nExamples\n\njulia> x = randn(ComplexF64, 2, 3, 4, 5);\njulia> x = permutedim(x, 2, 4);\njulia> size(x)\n(2, 4, 5, 3)\n\n\n\n\n\n","category":"function"},{"location":"tensors/#Combining-and-restoring-dimensions","page":"Tensors","title":"Combining & restoring dimensions","text":"","category":"section"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"Dimensions in a tensor can be combined into a single dimension, and restored using a key. This allows us to make efficient use of BLAS and LAPACK routines involving matrix operations. ","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"Combine the dimensions cixs of tensor x. This can be done in place with a pre-allocated tensor z using key = combinedims!(z, x, cixs), or otherwise z, key = combinedims(x, cixs). Note that, by default, the result will be stored in the memory cache (using keyword argument tocache). If the result is not some intermediate step, and you would like to save the resulting tensor for future use, then use tocache=false.","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"combinedims!\r\ncombinedims","category":"page"},{"location":"tensors/#TeNe.combinedims!","page":"Tensors","title":"TeNe.combinedims!","text":"combinedims!(y, x, cixs)\n\nCombine the dimensions cixs in tensor x, and store the result in y.\n\nExamples\n\njulia> x = randn(ComplexF64, 4, 5, 6, 7);\njulia> y = similar(x, (4, 7, 30));\njulia> key = combinedims!(y, x, (2, 3))\n((2, 3), (5, 6))\n\n\n\n\n\n","category":"function"},{"location":"tensors/#TeNe.combinedims","page":"Tensors","title":"TeNe.combinedims","text":"combinedims(x, cixs; kwargs...)\n\nCombine the dimensions cixs in tensor x. \n\nReturns the reshaped tensor, along with a key to restore the original permutations.\n\nOptional Keyword Arguments\n\n- `return_copy=false`: Return the result in newly allocated memory? Only\n   necessary if the combined dimensions are the last dimensions of `x`.\n\nExamples\n\njulia> x = randn(ComplexF64, 4, 5, 6, 7);\njulia> y, key = combinedims(x, (2, 3));\njulia> size(y)\n(4, 7, 30)\n\n\n\n\n\n","category":"function"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"After combining the dimensions, which returns a key, the dimensions of the tensor can be restored. This can be done in place with a pre-allocated tensor y using uncombinedims!(y, x, key), or otherwise y = uncombinedims(y, x, key). Note that, by default, the result will be stored in the memory cache (using keyword argument tocache). If the result is not some intermediate step, and you would like to save the resulting tensor for future use, then use tocache=false.","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"uncombinedims!\r\nuncombinedims","category":"page"},{"location":"tensors/#TeNe.uncombinedims!","page":"Tensors","title":"TeNe.uncombinedims!","text":"uncombinedims!(y, x, key)\n\nUncombine the end dimensions of x according to the key, and store the result in y.\n\nExamples\n\njulia> x = randn(ComplexF64, 4, 5, 6, 7);\njulia> z, key = combinedims(x, (2, 3));\njulia> y = similar(x);\njulia> isapprox(y, x);\ntrue\n\n\n\n\n\n","category":"function"},{"location":"tensors/#TeNe.uncombinedims","page":"Tensors","title":"TeNe.uncombinedims","text":"uncombinedims(x, key; kwargs...)\n\nUncombine the end dimension in tensor x according to the key.\n\nKey arguments\n\n- `return_copy=false`: Return the result in newly allocated memory? Only\n   necessary if the combined dimensions are the last dimensions of `x`.\n\nExamples\n\njulia> x = randn(ComplexF64, 4, 5, 6, 7);\njulia> y, key = combinedims(x, (2, 3));\njulia> z = uncombinedims(y, key);\njulia> size(z)\n(4, 5, 6, 7)\n\n\n\n\n\n","category":"function"},{"location":"tensors/#Tensor-factorisations","page":"Tensors","title":"Tensor factorisations","text":"","category":"section"},{"location":"tensors/#Singular-value-decomposition","page":"Tensors","title":"Singular value decomposition","text":"","category":"section"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"The singular value decomposition M = USV is typically applied to a matrix, but can equally be applied to a tensor to split the dimensions into separate tensors. This is done by permuting and reshaping the tensor into a matrix representation and applying the SVD. The dimensions to be contained in V are specified by dims, with U, S, V = tsvd(x, dims).","category":"page"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"tsvd","category":"page"},{"location":"tensors/#TeNe.tsvd","page":"Tensors","title":"TeNe.tsvd","text":"tsvd(x, dims; kwargs...)\ntsvd(x, dim::Int; kwargs...)\n\nComputer a singular value decomposition of tensor x. Seperates the dimensions dims from the remainder.\n\nOptional Keyword Arguments\n\n- `cutoff::Float64=0.0`: Truncation criteria to reduce the bond dimension.\n  Good values range from 1e-8 to 1e-14.\n- `mindim::Int=1`: Mininum dimension for truncated.\n- `maxdim::Int=0`: Maximum bond dimension for truncation. Set to 0 to have\n  no limit.\n\n\n\n\n\n","category":"function"},{"location":"tensors/","page":"Tensors","title":"Tensors","text":"At a later date, we would like to improve the SVD to pre-allocate memory in the cache for calculating the returns (and optional parameters to pre-allocated the memory to restore the results.)","category":"page"},{"location":"mps/#Matrix-product-states","page":"Matrix product states","title":"Matrix product states","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"Matrix product states are an ansatz for describing and estimating states of one-dimensional systems. In this package, MPS can be used for a variety of applications, e.g., ground state estimation, simulating dynamics, and quantum circuit calculations. ","category":"page"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"Pages = [\"mps.md\"]\r\nDepth = 3","category":"page"},{"location":"mps/#Matrix-product-states-(MPS)","page":"Matrix product states","title":"Matrix product states (MPS)","text":"","category":"section"},{"location":"mps/#Initiating-an-MPS","page":"Matrix product states","title":"Initiating an MPS","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"There are many ways to create an MPS, and the method will depend on the problem at hand.","category":"page"},{"location":"mps/#Random-states","page":"Matrix product states","title":"Random states","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"For variational problems, we sometimes recommend initiating an MPS randomly using ψ = randommps(dim, length, bonddim), where dim is the physical dimension of the lattice, length is the number of sites in the lattice, and bonddim is the bond dimension of the MPS.","category":"page"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"randommps","category":"page"},{"location":"mps/#TeNe.randommps","page":"Matrix product states","title":"TeNe.randommps","text":"randommps(dim::Int, length::Int, bonddim::Int)\n\nCreate an MPS with dimensions dim, size length and bond dimension bonddim, with random tensors.\n\nOptional Keyword Arguments\n\n- `T::Type=ComplexF64`: The element type for the tensors.\n\n\n\n\n\n","category":"function"},{"location":"mps/#Product-states","page":"Matrix product states","title":"Product states","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"An alternative option is to initalise the MPS is a state with known desirable properties.  This can be done in a few ways. The simplest way is to just provide a translationally invariant tensor A for the MPS (with bond dimension one), ψ = productmps(N, A).","category":"page"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"productmps(N::Int, A::Q) where {Q<:AbstractArray}","category":"page"},{"location":"mps/#TeNe.productmps-Union{Tuple{Q}, Tuple{Int64, Q}} where Q<:AbstractArray","page":"Matrix product states","title":"TeNe.productmps","text":"productmps(N::Int, A<:AbstractArray; kwargs...)\n\nCreate a product MPS of size N, composed of array A.  A can be a vector or rank-3 tensor.\n\nOptional Keyword Arguments\n\n- `T::Type=ComplexF64`: The element type for the tensors.\n- `normalise::Bool=false`: Normalise the MPS after creating it?\n\n\n\n\n\n","category":"method"},{"location":"mps/#Properties-of-an-MPS","page":"Matrix product states","title":"Properties of an MPS","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"rank(::GMPS)\r\ndim(::GMPS)\r\ncenter(::GMPS)\r\nbonddim(::GMPS, ::Int)\r\nmaxbonddim(::GMPS)\r\nnorm(::GMPS)","category":"page"},{"location":"mps/#TeNe.rank-Tuple{GMPS}","page":"Matrix product states","title":"TeNe.rank","text":"rank(::GMPS)\n\nReturns the rank of an MPS object.\n\n\n\n\n\n","category":"method"},{"location":"mps/#TeNe.dim-Tuple{GMPS}","page":"Matrix product states","title":"TeNe.dim","text":"dim(::GMPS)\n\nThe size of the physical dimensions in a GMPS. Returns 0 for heterogeneous  systems (i.e. an invariant physical dimension).\n\n\n\n\n\n","category":"method"},{"location":"mps/#TeNe.center-Tuple{GMPS}","page":"Matrix product states","title":"TeNe.center","text":"center(::GMPS)\n\nThe orthogonal center of an MPS. Returns 0 if nothing is set.\n\n\n\n\n\n","category":"method"},{"location":"mps/#TeNe.bonddim-Tuple{GMPS, Int64}","page":"Matrix product states","title":"TeNe.bonddim","text":"bonddim(::GMPS, idx::Int)\n\nReturn the bond dimension size between idx and idx + 1. Returns nothing if out of range.\n\n\n\n\n\n","category":"method"},{"location":"mps/#TeNe.maxbonddim-Tuple{GMPS}","page":"Matrix product states","title":"TeNe.maxbonddim","text":"maxbonddim(::GMPS)\n\nCalculate the maximum bond dimension within an GMPS.\n\n\n\n\n\n","category":"method"},{"location":"mps/#LinearAlgebra.norm-Tuple{GMPS}","page":"Matrix product states","title":"LinearAlgebra.norm","text":"norm(ψ::GMPS)\n\nCalculate the norm of an GMPS.\n\n\n\n\n\n","category":"method"},{"location":"mps/#Manipulations-of-an-MPS","page":"Matrix product states","title":"Manipulations of an MPS","text":"","category":"section"},{"location":"mps/#Normalization","page":"Matrix product states","title":"Normalization","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"normalize!(::GMPS)","category":"page"},{"location":"mps/#LinearAlgebra.normalize!-Tuple{GMPS}","page":"Matrix product states","title":"LinearAlgebra.normalize!","text":"normalize!(ψ::GMPS)\n\nNormalize a GMPS.\n\n\n\n\n\n","category":"method"},{"location":"mps/#Canonical-center","page":"Matrix product states","title":"Canonical center","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"An important property of MPS is that they can be brought into a canonical representation, allowing for better conditioned calculations and simplifications in many MPS algorithms. The canonical center of an MPS ψ is easily moved to idx using movecenter!(ψ, idx). This also allows for dynamic truncation of the MPS, using keyword arguments such as maxdim or cutoff.","category":"page"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"movecenter!(ψ::GMPS, idx::Int)","category":"page"},{"location":"mps/#TeNe.movecenter!-Tuple{GMPS, Int64}","page":"Matrix product states","title":"TeNe.movecenter!","text":"movecenter!(ψ::GMPS, idx::Int; kwargs...)\n\nMove the orthogonal center of an GMPS ψ to idx.\n\nOptional Keyword Arguments\n\n- `cutoff::Float64=0.0`: Truncation criteria to reduce the bond dimension.\n  Good values range from 1e-8 to 1e-14.\n- `mindim::Int=1`: Minimum dimension for the truncation.\n- `maxdim::Int=0`: Maximum bond dimension for truncation. Set to 0 to have\n  no limit.\n\n\n\n\n\n","category":"method"},{"location":"mps/#Truncations","page":"Matrix product states","title":"Truncations","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"The bond dimension of the MPS controls its accuracy. A larger bond dimension has a higher capacity for precision, but also increases the computational cost of algorithms. To reduce the bond dimension (and sacrificing as little accuracy as possible), one can truncate the MPS.","category":"page"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"truncate!(::GMPS)","category":"page"},{"location":"mps/#TeNe.truncate!-Tuple{GMPS}","page":"Matrix product states","title":"TeNe.truncate!","text":"truncate!(ψ::GMPS; kwargs...)\n\nTruncate the bond dimension of a GMPS ψ.\n\nOptional Keyword Arguments\n\n- `cutoff::Float64=0.0`: Truncation criteria to reduce the bond dimension.\nGood values range from 1e-8 to 1e-14.\n- `mindim::Int=1`: Minimum dimension for the truncation.\n- `maxdim::Int=0`: Maximum bond dimension for truncation. Set to 0 to have\nno limit.\n\n\n\n\n\n","category":"method"},{"location":"mps/#Inner-products","page":"Matrix product states","title":"Inner products","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"Some linear algebra operations such as the inner product are easy to calculate for MPS.","category":"page"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"inner(ψ::MPS, ϕ::MPS)","category":"page"},{"location":"mps/#TeNe.inner-Tuple{MPS, MPS}","page":"Matrix product states","title":"TeNe.inner","text":"inner(ψ::MPS, ϕ::MPS)\ndot(ψ::MPS, ϕ::MPS)\n*(ψ::MPS, ϕ::MPS)\n\nCalculate the inner product of two MPSs ψ and ϕ.\n\n\n\n\n\n","category":"method"},{"location":"mps/#Matrix-product-operators-(MPO)","page":"Matrix product states","title":"Matrix product operators (MPO)","text":"","category":"section"},{"location":"mps/","page":"Matrix product states","title":"Matrix product states","text":"Just as a wavefunction, or state vector, can be represented as an MPS, an operator can be represented by a matrix product operator.","category":"page"},{"location":"mps/#Initiating-an-MPO","page":"Matrix product states","title":"Initiating an MPO","text":"","category":"section"},{"location":"mps/#Construct-an-MPO-from-an-operator-list","page":"Matrix product states","title":"Construct an MPO from an operator list","text":"","category":"section"},{"location":"mps/#Manipulate-an-MPO","page":"Matrix product states","title":"Manipulate an MPO","text":"","category":"section"},{"location":"mps/#Inner-products-2","page":"Matrix product states","title":"Inner products","text":"","category":"section"},{"location":"mps/#Advanced-usage:-Generalised-matrix-product-states-(GMPS)","page":"Matrix product states","title":"Advanced usage: Generalised matrix product states (GMPS)","text":"","category":"section"},{"location":"#TeNe.jl-Documentation","page":"Introduction","title":"TeNe.jl Documentation","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"","category":"page"}]
}
